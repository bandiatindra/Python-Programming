{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Classification 4\n",
    "\n",
    "We are going to look at Decision Trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We will analyze the _Titanic_ dataset, containing features of the people on the Titanic, and whether they survived or not. Data can be found [here](http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt).\n",
    "\n",
    "We will use Decision Trees to answer super-important questions like:\n",
    "\n",
    "**Will Leo di Caprio make it out alive?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(Hint: Nah.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "from patsy import dmatrices\n",
    "import warnings\n",
    "%pylab inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['row.names', 'pclass', 'survived', 'name', 'age', 'embarked',\n",
       "       'home.dest', 'room', 'ticket', 'boat', 'sex'], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt')\n",
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many passengers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1313"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Show me one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row.names                               1\n",
       "pclass                                1st\n",
       "survived                                1\n",
       "name         Allen, Miss Elisabeth Walton\n",
       "age                                    29\n",
       "embarked                      Southampton\n",
       "home.dest                    St Louis, MO\n",
       "room                                  B-5\n",
       "ticket                         24160 L221\n",
       "boat                                    2\n",
       "sex                                female\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Southampton    573\n",
       "Cherbourg      203\n",
       "Queenstown      45\n",
       "Name: embarked, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['embarked'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create the design matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y, X = dmatrices('survived ~ 0 + pclass + age + embarked + sex', df, return_type='dataframe')\n",
    "y = Y['survived'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass[1st]</th>\n",
       "      <th>pclass[2nd]</th>\n",
       "      <th>pclass[3rd]</th>\n",
       "      <th>embarked[T.Queenstown]</th>\n",
       "      <th>embarked[T.Southampton]</th>\n",
       "      <th>sex[T.male]</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass[1st]  pclass[2nd]  pclass[3rd]  embarked[T.Queenstown]  \\\n",
       "0          1.0          0.0          0.0                     0.0   \n",
       "1          1.0          0.0          0.0                     0.0   \n",
       "2          1.0          0.0          0.0                     0.0   \n",
       "3          1.0          0.0          0.0                     0.0   \n",
       "4          1.0          0.0          0.0                     0.0   \n",
       "\n",
       "   embarked[T.Southampton]  sex[T.male]      age  \n",
       "0                      1.0          0.0  29.0000  \n",
       "1                      1.0          0.0   2.0000  \n",
       "2                      1.0          1.0  30.0000  \n",
       "3                      1.0          0.0  25.0000  \n",
       "4                      1.0          1.0   0.9167  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Set up classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier(criterion='entropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "result = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9246575342465754\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "prediction_train = model.predict(X_train)\n",
    "print metrics.accuracy_score(y_train, prediction_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7724867724867724\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is far worse than the 92% accuracy we expected from the training set. Clearly, we are **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to avoid overfitting is to ensure that trees never become too deep, via the *max\\_depth* argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=2)\n",
    "result = model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8287671232876712\n"
     ]
    }
   ],
   "source": [
    "prediction_train = model2.predict(X_train)\n",
    "print metrics.accuracy_score(y_train, prediction_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "prediction = model2.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What does the tree look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from StringIO import StringIO\n",
    "import pydot_ng\n",
    "dot_data = StringIO()\n",
    "tree.export_graphviz(model2, out_file=dot_data, feature_names=X.columns.values)\n",
    "pydot_ng.graph_from_dot_data(dot_data.getvalue()).write_png('Classification_4_data/titanic2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Decision Tree](Classification_4_data/titanic2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each node of the decision tree checks a feature value\n",
    "    * If the answer is _Yes_, take the left branch\n",
    "    * else take the right branch.\n",
    "* Root node in the tree checks if sex[T.male] <= 0.5. sex[T.male] is 1 if male and 0 if female, so it is less than 0.5 for females.\n",
    "    * If _Yes_ (left branch), check if pclass[3rd] is 0, etc.\n",
    "* A leaf node has _value_ (i.e., class label) as a list:\n",
    "    * first item of list is class label 0 (negative class)\n",
    "    * second list item is class label 1 (positive class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "    if sex=female:\n",
    "        if not 3rd class passenger:\n",
    "            return \"likely survives: probability 117/125\"\n",
    "        else:\n",
    "            return \"likely dies: probability 22/37\"\n",
    "    else:\n",
    "        if age <= 4.5 years (baby):\n",
    "            return \"always survives\"\n",
    "        else:\n",
    "            return \"likely dies: probability 52/265\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even though port of embarkation was a feature, it was not discriminative enough to be included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What did our first model (with possible overfitting) look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = StringIO()\n",
    "tree.export_graphviz(model, out_file=dot_data, feature_names=X.columns.values)\n",
    "pydot_ng.graph_from_dot_data(dot_data.getvalue()).write_png('Classification_4_data/titanic1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Titanic overfitting](Classification_4_data/titanic1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let us try decision trees on another problem: guessing the income level of an adult. We saw this problem earlier when we tried Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                          39\n",
       "workclass             State-gov\n",
       "fnlwgt                    77516\n",
       "education             Bachelors\n",
       "education_num                13\n",
       "marital_status    Never-married\n",
       "occupation         Adm-clerical\n",
       "relationship      Not-in-family\n",
       "race                      White\n",
       "sex                        Male\n",
       "capital_gain               2174\n",
       "capital_loss                  0\n",
       "hours_per_week               40\n",
       "native_country    United-States\n",
       "income_band               <=50K\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', \\\n",
    "         'marital_status', 'occupation', 'relationship', 'race', 'sex', \\\n",
    "         'capital_gain', 'capital_loss', 'hours_per_week', \\\n",
    "         'native_country', 'income_band']\n",
    "df = pd.read_table('Classification_2_data/adult.data', sep=', ', names=names)\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = 0.0\n",
    "mask = (df['income_band'] == '>50K')\n",
    "df['target'][mask] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the design matrices\n",
    "\n",
    "With Naive Bayes, we had to properly bin the data (e.g., hours worked, capital gains, etc.) A decision tree should be able to figure out the right split thresholds by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'target ~ 0 + age + workclass + fnlwgt + education + education_num + ' \\\n",
    "          'marital_status + occupation + relationship + race + sex + ' \\\n",
    "          'capital_gain + capital_loss + hours_per_week'\n",
    "Y, X = dmatrices(formula, df, return_type='dataframe')\n",
    "y = Y['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split intro training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Set up the classifier\n",
    "\n",
    "We saw that getting the right _max\\_depth_ was important to avoid overfitting. Let us try cross-validation for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=1 scores=[0.75335615 0.75332368 0.75332368] avg_score=0.753334502385\n",
      "max_depth=2 scores=[0.79586733 0.82637883 0.82690536] avg_score=0.816383841546\n",
      "max_depth=3 scores=[0.83877336 0.8428327  0.84401738] avg_score=0.841874477936\n",
      "max_depth=4 scores=[0.84482759 0.83769909 0.8424378 ] avg_score=0.84165482745\n",
      "max_depth=5 scores=[0.84535404 0.83756746 0.84664999] avg_score=0.843190498265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Create the folds in the training data\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "\n",
    "# Iterate over max_depth\n",
    "for max_depth in [1, 2, 3, 4, 5]:\n",
    "    model3 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=max_depth)\n",
    "    scores = cross_val_score(model3, X_train, y_train, cv=kfold)\n",
    "    print 'max_depth={} scores={} avg_score={}'.format(max_depth, scores, scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's pick the smallest tree that works well: **max\\_depth=3**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fit with max_depth=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "result = model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8418743418743418\n"
     ]
    }
   ],
   "source": [
    "prediction_train = model3.predict(X_train)\n",
    "print metrics.accuracy_score(y_train, prediction_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This matches what we got from the cross-validation output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8481932644078206\n"
     ]
    }
   ],
   "source": [
    "prediction = model3.predict(X_test)\n",
    "print metrics.accuracy_score(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is in the same ballpark as the training accuracy, so we didn't overfit. All thanks to cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, Naive Bayes got 82.5%, so Decision Trees outperform Naive Bayes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What does the tree look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = StringIO()\n",
    "tree.export_graphviz(model3, out_file=dot_data, feature_names=X.columns.values)\n",
    "pydot_ng.graph_from_dot_data(dot_data.getvalue()).write_png('Classification_4_data/incomes.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Adult income tree](Classification_4_data/incomes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Primary split based on marital status\n",
    "    * The leaves in the left subtree (not married) are generally biased towards the negative class (income below 50K)\n",
    "    * Being in the higher-income bracket is more likely in the right subtree.\n",
    "    * This is precisely why the Decision Tree Classifier chose marriage as the first split.\n",
    "* After marital status, the education level and capital gains are enough to classify most of the data.\n",
    "    * Higher capital gains $\\Rightarrow$ more chances of being in the high-income class (Duh)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
